"""
PromptMinder æ•°æ®è¿ç§»è„šæœ¬
ä» Supabase CSV å¯¼å‡ºå¯¼å…¥åˆ° Neon PostgreSQL

ç”¨æ³•: python import_all.py
"""

import os
import pandas as pd
from sqlalchemy import create_engine, text

# â”€â”€ é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé¿å…ç¡¬ç¼–ç å¯†ç 
CONN_STR = os.environ.get("NEON_DATABASE_URL")
if not CONN_STR:
    print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ NEON_DATABASE_URL")
    print("ç¤ºä¾‹: export NEON_DATABASE_URL='postgresql://user:pass@host/db?sslmode=require'")
    exit(1)

CSV_DIR = os.path.dirname(os.path.abspath(__file__))

# å¯¼å…¥é¡ºåºï¼ˆæŒ‰å¤–é”®ä¾èµ–æ’åˆ—ï¼‰
IMPORT_ORDER = [
    # ç¬¬1å±‚ï¼šæ— å¤–é”®ä¾èµ–
    "teams",
    "public_prompts",
    "prompt_contributions",
    "user_feedback",
    "provider_keys",
    # ç¬¬2å±‚ï¼šä¾èµ–ç¬¬1å±‚
    "team_members",      # FK â†’ teams
    "prompts",           # FK â†’ teams
    # ç¬¬3å±‚ï¼šä¾èµ–ç¬¬2å±‚
    "tags",              # FK â†’ teams
    "favorites",         # FK â†’ prompts
    "prompt_likes",      # FK â†’ public_prompts
]


# â”€â”€ æ•°æ®æ¸…æ´—å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clean_favorites(df, prompts_df):
    """æ¸…ç†å¼•ç”¨äº†ä¸å­˜åœ¨ prompt çš„æ”¶è—è®°å½•"""
    valid_ids = set(prompts_df["id"].dropna())
    before = len(df)
    df = df[df["prompt_id"].isin(valid_ids)]
    removed = before - len(df)
    if removed > 0:
        print(f"  âš  favorites: æ¸…ç†äº† {removed} æ¡å­¤å„¿è®°å½•ï¼ˆå¼•ç”¨ä¸å­˜åœ¨çš„ promptï¼‰")
    return df


def clean_prompt_likes(df, public_prompts_df):
    """æ¸…ç†å¼•ç”¨äº†ä¸å­˜åœ¨ public_prompt çš„ç‚¹èµè®°å½•"""
    valid_ids = set(public_prompts_df["id"].dropna())
    before = len(df)
    df = df[df["prompt_id"].isin(valid_ids)]
    removed = before - len(df)
    if removed > 0:
        print(f"  âš  prompt_likes: æ¸…ç†äº† {removed} æ¡å­¤å„¿è®°å½•ï¼ˆå¼•ç”¨ä¸å­˜åœ¨çš„ public_promptï¼‰")
    return df


def clean_tags(df):
    """tags è¡¨åœ¨ Supabase ä¸­æ²¡æœ‰ created_by å’Œ updated_atï¼Œéœ€è¦è¡¥å……"""
    # æ¸…ç† team_id å’Œ user_id éƒ½ä¸ºç©ºçš„å­¤å„¿æ ‡ç­¾ï¼ˆè¿å chk_tag_scope çº¦æŸï¼‰
    orphan_mask = df["team_id"].isna() & df["user_id"].isna()
    orphan_count = orphan_mask.sum()
    if orphan_count > 0:
        df = df[~orphan_mask]
        print(f"  âš  tags: æ¸…ç†äº† {orphan_count} æ¡å­¤å„¿è®°å½•ï¼ˆteam_id å’Œ user_id éƒ½ä¸ºç©ºï¼‰")
    if "created_by" not in df.columns:
        # ç”¨ user_id å¡«å…… created_byï¼ˆä¸ªäººæ ‡ç­¾åœºæ™¯ï¼‰
        df["created_by"] = df.get("user_id", None)
        print("  âš  tags: è¡¥å……äº† created_by åˆ—ï¼ˆä½¿ç”¨ user_id çš„å€¼ï¼‰")
    if "updated_at" not in df.columns:
        # ç”¨ created_at å¡«å…… updated_at
        df["updated_at"] = df["created_at"]
        print("  âš  tags: è¡¥å……äº† updated_at åˆ—ï¼ˆä½¿ç”¨ created_at çš„å€¼ï¼‰")
    return df


# â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_csv(table_name):
    """åŠ è½½ CSV æ–‡ä»¶"""
    csv_path = os.path.join(CSV_DIR, f"{table_name}_rows.csv")
    if not os.path.exists(csv_path):
        return None
    return pd.read_csv(csv_path)


def main():
    engine = create_engine(CONN_STR)

    # é¢„åŠ è½½éœ€è¦åšå¤–é”®æ ¡éªŒçš„æ•°æ®
    prompts_df = load_csv("prompts")
    public_prompts_df = load_csv("public_prompts")

    success_count = 0
    skip_count = 0
    fail_count = 0

    for table_name in IMPORT_ORDER:
        csv_path = os.path.join(CSV_DIR, f"{table_name}_rows.csv")

        if not os.path.exists(csv_path):
            print(f"â­ {table_name}: CSV æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            skip_count += 1
            continue

        print(f"ğŸ“¦ æ­£åœ¨å¯¼å…¥ {table_name}...")

        try:
            df = pd.read_csv(csv_path)
            original_count = len(df)

            # æ•°æ®æ¸…æ´—
            if table_name == "favorites" and prompts_df is not None:
                df = clean_favorites(df, prompts_df)
            elif table_name == "prompt_likes" and public_prompts_df is not None:
                df = clean_prompt_likes(df, public_prompts_df)
            elif table_name == "tags":
                df = clean_tags(df)

            if len(df) == 0:
                print(f"  â­ {table_name}: æ¸…æ´—åæ— æ•°æ®ï¼Œè·³è¿‡")
                skip_count += 1
                continue

            # å¯¼å…¥æ•°æ®
            df.to_sql(
                table_name,
                engine,
                if_exists="append",
                index=False,
                method="multi",
            )

            print(f"  âœ… {table_name}: æˆåŠŸå¯¼å…¥ {len(df)}/{original_count} æ¡")
            success_count += 1

        except Exception as e:
            print(f"  âŒ {table_name}: å¯¼å…¥å¤±è´¥ - {e}")
            fail_count += 1

    # æ±‡æ€»
    print("\n" + "=" * 50)
    print(f"å¯¼å…¥å®Œæˆ: âœ… æˆåŠŸ {success_count} | â­ è·³è¿‡ {skip_count} | âŒ å¤±è´¥ {fail_count}")
    print("=" * 50)

    # éªŒè¯ï¼šæŸ¥è¯¢æ¯å¼ è¡¨çš„è¡Œæ•°
    print("\nğŸ“Š æ•°æ®åº“è¡¨è¡Œæ•°éªŒè¯:")
    with engine.connect() as conn:
        for table_name in IMPORT_ORDER:
            try:
                result = conn.execute(text(f'SELECT COUNT(*) FROM "{table_name}"'))
                count = result.scalar()
                print(f"  {table_name}: {count} æ¡")
            except Exception:
                print(f"  {table_name}: æŸ¥è¯¢å¤±è´¥")


if __name__ == "__main__":
    main()